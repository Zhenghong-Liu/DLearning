{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17a0bd96",
   "metadata": {},
   "source": [
    "# 下载数据集\n",
    "\n",
    "从 https://huggingface.co/datasets/Helsinki-NLP/opus-100/tree/main/en-zh 下载了三个文件。\n",
    "\n",
    "使用下面的代码块保存成合适的dataset的格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dca1ad72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 1000000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 2000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 2000\n",
      "    })\n",
      "})\n",
      "{'translation': {'en': 'Sixty-first session', 'zh': '第六十一届会议'}}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7d8dae4c7fa49ee82d6eb5a473ab12e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1000000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c97caead43c04d32bf00a68751d691f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0101ffbca10c40bba5132070fae3e103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# 直接加载本地Parquet文件\n",
    "dataset = load_dataset(\n",
    "    \"parquet\",\n",
    "    data_files={\n",
    "        \"train\": \"/home/liuzh/project/DLearning/data/opus100_en_zh/data/train-00000-of-00001.parquet\",\n",
    "        \"validation\": \"/home/liuzh/project/DLearning/data/opus100_en_zh/data/validation-00000-of-00001.parquet\",\n",
    "        \"test\": \"/home/liuzh/project/DLearning/data/opus100_en_zh/data/test-00000-of-00001.parquet\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# 验证数据集结构\n",
    "print(dataset)\n",
    "print(dataset[\"train\"][0])  # 查看第一条数据\n",
    "\n",
    "# 保存为完整数据集格式（会自动生成缺失的元数据文件）\n",
    "dataset.save_to_disk(\"/home/liuzh/project/DLearning/data/opus100_en_zh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d52d1dc",
   "metadata": {},
   "source": [
    "# 构造Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07885871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 1000000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 2000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 2000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "# 加载本地数据集\n",
    "local_dataset = DatasetDict.load_from_disk(\"/home/liuzh/project/DLearning/data/opus100_en_zh\")\n",
    "print(local_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9b5b589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'第六十一届会议'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_dataset['train'][0]['translation']['zh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09fb530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "def build_tokenizer(texts, max_vocab=5000):\n",
    "    tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
    "    tokenizer.pre_tokenizer = Whitespace()\n",
    "    trainer = WordLevelTrainer(\n",
    "        special_tokens=[\"[PAD]\", \"[UNK]\", \"[SOS]\", \"[EOS]\"],\n",
    "        min_frequency=2\n",
    "    )\n",
    "    \n",
    "    counter = Counter()\n",
    "    for text in texts:\n",
    "        counter.update(text.split())\n",
    "    \n",
    "    vocab = [\"[PAD]\", \"[UNK]\", \"[SOS]\", \"[EOS]\"] + \\\n",
    "            [word for word, count in counter.most_common(max_vocab-4)]\n",
    "    \n",
    "    tokenizer.train_from_iterator(\n",
    "        [vocab],\n",
    "        trainer=trainer,\n",
    "        length=len(vocab)\n",
    "    )\n",
    "    return tokenizer\n",
    "\n",
    "# 示例用法（实际应使用完整数据）\n",
    "zh_tokenizer = build_tokenizer([ex['translation'][\"zh\"] for ex in local_dataset[\"train\"].select(range(1000))])\n",
    "en_tokenizer = build_tokenizer([ex['translation'][\"en\"] for ex in local_dataset[\"train\"].select(range(1000))])\n",
    "\n",
    "# 保存/加载分词器\n",
    "zh_tokenizer.save(\"zh_tokenizer.json\")\n",
    "en_tokenizer.save(\"en_tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2eb4a8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, dataset, zh_tokenizer, en_tokenizer, max_length=100):\n",
    "        self.dataset = dataset\n",
    "        self.zh_tokenizer = zh_tokenizer\n",
    "        self.en_tokenizer = en_tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pair = self.dataset[idx]\n",
    "        # print(pair)\n",
    "        zh = pair['translation'][\"zh\"]\n",
    "        en = pair['translation'][\"en\"]\n",
    "        \n",
    "        # 中文编码\n",
    "        zh_encoded = [self.zh_tokenizer.token_to_id(\"[SOS]\")] + \\\n",
    "                     self.zh_tokenizer.encode(zh).ids[:self.max_length-2] + \\\n",
    "                     [self.zh_tokenizer.token_to_id(\"[EOS]\")]\n",
    "        \n",
    "        # 英文编码\n",
    "        en_encoded = [self.en_tokenizer.token_to_id(\"[SOS]\")] + \\\n",
    "                    self.en_tokenizer.encode(en).ids[:self.max_length-2] + \\\n",
    "                    [self.en_tokenizer.token_to_id(\"[EOS]\")]\n",
    "        \n",
    "        return {\n",
    "            \"src\": torch.tensor(zh_encoded),\n",
    "            \"tgt\": torch.tensor(en_encoded)\n",
    "        }\n",
    "\n",
    "def collate_fn(batch):\n",
    "    src_batch = [item[\"src\"] for item in batch]\n",
    "    tgt_batch = [item[\"tgt\"] for item in batch]\n",
    "    \n",
    "    src_padded = torch.nn.utils.rnn.pad_sequence(\n",
    "        src_batch, padding_value=0, batch_first=True\n",
    "    )\n",
    "    tgt_padded = torch.nn.utils.rnn.pad_sequence(\n",
    "        tgt_batch, padding_value=0, batch_first=True\n",
    "    )\n",
    "    \n",
    "    return src_padded, tgt_padded\n",
    "\n",
    "# 示例用法\n",
    "train_dataset = TranslationDataset(local_dataset[\"train\"].select(range(1000)), zh_tokenizer, en_tokenizer)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffab48f2",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ed4c9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(1), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class TransformerTranslator(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        src_vocab_size,\n",
    "        tgt_vocab_size,\n",
    "        d_model=512,\n",
    "        nhead=8,\n",
    "        num_encoder_layers=6,\n",
    "        num_decoder_layers=6,\n",
    "        dim_feedforward=2048,\n",
    "        dropout=0.1,\n",
    "        max_seq_length=100\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # 嵌入层\n",
    "        self.src_embedding = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.tgt_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout, max_seq_length)\n",
    "        \n",
    "        # 编码器\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model, nhead, dim_feedforward, dropout, batch_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_encoder_layers)\n",
    "        \n",
    "        # 解码器\n",
    "        decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model, nhead, dim_feedforward, dropout, batch_first=True\n",
    "        )\n",
    "        self.decoder = nn.TransformerDecoder(decoder_layer, num_decoder_layers)\n",
    "        \n",
    "        # 输出层\n",
    "        self.output_layer = nn.Linear(d_model, tgt_vocab_size)\n",
    "\n",
    "    def forward(self, src, tgt, src_mask=None, tgt_mask=None, memory_mask=None):\n",
    "        # 编码器\n",
    "        src_emb = self.pos_encoder(self.src_embedding(src))\n",
    "        memory = self.encoder(src_emb, src_mask)\n",
    "        \n",
    "        # 解码器\n",
    "        tgt_emb = self.pos_encoder(self.tgt_embedding(tgt))\n",
    "        output = self.decoder(\n",
    "            tgt_emb,\n",
    "            memory,\n",
    "            tgt_mask=tgt_mask,\n",
    "            memory_mask=memory_mask\n",
    "        )\n",
    "        \n",
    "        return self.output_layer(output)\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        return torch.triu(torch.full((sz, sz), float('-inf')), diagonal=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9f21e7",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9cb5c3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.2404\n",
      "Epoch 2, Loss: 3.8806\n",
      "Epoch 3, Loss: 3.6207\n",
      "Epoch 4, Loss: 3.4016\n",
      "Epoch 5, Loss: 3.2262\n",
      "Epoch 6, Loss: 3.0965\n",
      "Epoch 7, Loss: 2.9784\n",
      "Epoch 8, Loss: 2.8831\n",
      "Epoch 9, Loss: 2.7951\n",
      "Epoch 10, Loss: 2.7092\n",
      "Epoch 11, Loss: 2.6090\n",
      "Epoch 12, Loss: 2.5170\n",
      "Epoch 13, Loss: 2.4599\n",
      "Epoch 14, Loss: 2.3680\n",
      "Epoch 15, Loss: 2.2788\n",
      "Epoch 16, Loss: 2.2030\n",
      "Epoch 17, Loss: 2.1320\n",
      "Epoch 18, Loss: 2.0576\n",
      "Epoch 19, Loss: 1.9960\n",
      "Epoch 20, Loss: 1.9057\n",
      "Epoch 21, Loss: 1.8525\n",
      "Epoch 22, Loss: 1.7796\n",
      "Epoch 23, Loss: 1.7123\n",
      "Epoch 24, Loss: 1.6419\n",
      "Epoch 25, Loss: 1.5713\n",
      "Epoch 26, Loss: 1.5013\n",
      "Epoch 27, Loss: 1.4369\n",
      "Epoch 28, Loss: 1.3869\n",
      "Epoch 29, Loss: 1.3482\n",
      "Epoch 30, Loss: 1.2736\n",
      "Epoch 31, Loss: 1.2224\n",
      "Epoch 32, Loss: 1.1647\n",
      "Epoch 33, Loss: 1.1305\n",
      "Epoch 34, Loss: 1.0794\n",
      "Epoch 35, Loss: 1.0342\n",
      "Epoch 36, Loss: 0.9905\n",
      "Epoch 37, Loss: 0.9620\n",
      "Epoch 38, Loss: 0.9249\n",
      "Epoch 39, Loss: 0.8921\n",
      "Epoch 40, Loss: 0.8537\n",
      "Epoch 41, Loss: 0.8115\n",
      "Epoch 42, Loss: 0.8070\n",
      "Epoch 43, Loss: 0.7754\n",
      "Epoch 44, Loss: 0.7531\n",
      "Epoch 45, Loss: 0.7085\n",
      "Epoch 46, Loss: 0.6857\n",
      "Epoch 47, Loss: 0.6685\n",
      "Epoch 48, Loss: 0.6492\n",
      "Epoch 49, Loss: 0.6315\n",
      "Epoch 50, Loss: 0.6061\n",
      "Epoch 51, Loss: 0.6008\n",
      "Epoch 52, Loss: 0.5785\n",
      "Epoch 53, Loss: 0.5501\n",
      "Epoch 54, Loss: 0.5375\n",
      "Epoch 55, Loss: 0.5229\n",
      "Epoch 56, Loss: 0.5226\n",
      "Epoch 57, Loss: 0.5124\n",
      "Epoch 58, Loss: 0.5121\n",
      "Epoch 59, Loss: 0.4855\n",
      "Epoch 60, Loss: 0.4766\n",
      "Epoch 61, Loss: 0.4740\n",
      "Epoch 62, Loss: 0.4699\n",
      "Epoch 63, Loss: 0.4439\n",
      "Epoch 64, Loss: 0.4315\n",
      "Epoch 65, Loss: 0.4181\n",
      "Epoch 66, Loss: 0.4266\n",
      "Epoch 67, Loss: 0.4223\n",
      "Epoch 68, Loss: 0.4033\n",
      "Epoch 69, Loss: 0.3904\n",
      "Epoch 70, Loss: 0.3918\n",
      "Epoch 71, Loss: 0.3826\n",
      "Epoch 72, Loss: 0.3718\n",
      "Epoch 73, Loss: 0.3600\n",
      "Epoch 74, Loss: 0.3644\n",
      "Epoch 75, Loss: 0.3615\n",
      "Epoch 76, Loss: 0.3623\n",
      "Epoch 77, Loss: 0.3441\n",
      "Epoch 78, Loss: 0.3335\n",
      "Epoch 79, Loss: 0.3202\n",
      "Epoch 80, Loss: 0.3346\n",
      "Epoch 81, Loss: 0.3233\n",
      "Epoch 82, Loss: 0.3203\n",
      "Epoch 83, Loss: 0.3117\n",
      "Epoch 84, Loss: 0.3173\n",
      "Epoch 85, Loss: 0.3209\n",
      "Epoch 86, Loss: 0.3124\n",
      "Epoch 87, Loss: 0.3091\n",
      "Epoch 88, Loss: 0.3058\n",
      "Epoch 89, Loss: 0.2944\n",
      "Epoch 90, Loss: 0.2932\n",
      "Epoch 91, Loss: 0.2754\n",
      "Epoch 92, Loss: 0.2769\n",
      "Epoch 93, Loss: 0.2698\n",
      "Epoch 94, Loss: 0.2617\n",
      "Epoch 95, Loss: 0.2621\n",
      "Epoch 96, Loss: 0.2559\n",
      "Epoch 97, Loss: 0.2574\n",
      "Epoch 98, Loss: 0.2553\n",
      "Epoch 99, Loss: 0.2496\n",
      "Epoch 100, Loss: 0.2541\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 模型参数\n",
    "SRC_VOCAB_SIZE = zh_tokenizer.get_vocab_size()\n",
    "TGT_VOCAB_SIZE = en_tokenizer.get_vocab_size()\n",
    "model = TransformerTranslator(SRC_VOCAB_SIZE, TGT_VOCAB_SIZE).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "def train_epoch(model, dataloader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for src, tgt in dataloader:\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "        \n",
    "        # 生成mask\n",
    "        tgt_input = tgt[:, :-1]\n",
    "        tgt_output = tgt[:, 1:]\n",
    "        tgt_mask = model.generate_square_subsequent_mask(tgt_input.size(1)).to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, tgt_input, tgt_mask=tgt_mask)\n",
    "        \n",
    "        loss = criterion(\n",
    "            output.reshape(-1, output.size(-1)),\n",
    "            tgt_output.reshape(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# 训练多个epoch\n",
    "for epoch in range(100):\n",
    "    loss = train_epoch(model, train_loader)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76beb48a",
   "metadata": {},
   "source": [
    "# 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5febdf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "# 保存模型（训练完成后执行）\n",
    "def save_model(model, optimizer, tokenizers, save_dir=\"./translator_model\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # 保存模型参数\n",
    "    torch.save({\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"optimizer_state\": optimizer.state_dict(),\n",
    "    }, f\"{save_dir}/model.pth\")\n",
    "    \n",
    "    # 保存分词器\n",
    "    zh_tokenizer.save(f\"{save_dir}/zh_tokenizer.json\")\n",
    "    en_tokenizer.save(f\"{save_dir}/en_tokenizer.json\")\n",
    "\n",
    "# 加载模型\n",
    "def load_model(save_dir=\"./translator_model\", device=\"cpu\"):\n",
    "    # 初始化空模型\n",
    "    zh_tokenizer = Tokenizer.from_file(f\"{save_dir}/zh_tokenizer.json\")\n",
    "    en_tokenizer = Tokenizer.from_file(f\"{save_dir}/en_tokenizer.json\")\n",
    "    \n",
    "    model = TransformerTranslator(\n",
    "        src_vocab_size=zh_tokenizer.get_vocab_size(),\n",
    "        tgt_vocab_size=en_tokenizer.get_vocab_size()\n",
    "    ).to(device)\n",
    "    \n",
    "    checkpoint = torch.load(f\"{save_dir}/model.pth\", map_location=device)\n",
    "    model.load_state_dict(checkpoint[\"model_state\"])\n",
    "    \n",
    "    return model, zh_tokenizer, en_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a07102d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练完成后保存模型\n",
    "save_model(model, optimizer, (zh_tokenizer, en_tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410c93fc",
   "metadata": {},
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d372db5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_translate(model, zh_tokenizer, en_tokenizer, device=\"cpu\", max_length=50):\n",
    "    model.eval()\n",
    "    print(\"输入中文进行翻译（输入 'exit' 退出）:\")\n",
    "    \n",
    "    while True:\n",
    "        text = input(\">>> \").strip()\n",
    "        if text.lower() == \"exit\":\n",
    "            break\n",
    "        if not text:\n",
    "            continue\n",
    "        \n",
    "        # 编码输入\n",
    "        input_ids = [zh_tokenizer.token_to_id(\"[SOS]\")] \n",
    "        input_ids += zh_tokenizer.encode(text).ids\n",
    "        input_ids.append(zh_tokenizer.token_to_id(\"[EOS]\"))\n",
    "        \n",
    "        src = torch.tensor([input_ids], dtype=torch.long, device=device)\n",
    "        \n",
    "        # 生成翻译\n",
    "        output_ids = [en_tokenizer.token_to_id(\"[SOS]\")]\n",
    "        for _ in range(max_length):\n",
    "            tgt = torch.tensor([output_ids], dtype=torch.long, device=device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                output = model(src, tgt)\n",
    "            \n",
    "            next_id = output.argmax(-1)[:, -1].item()\n",
    "            output_ids.append(next_id)\n",
    "            \n",
    "            if next_id == en_tokenizer.token_to_id(\"[EOS]\"):\n",
    "                break\n",
    "        \n",
    "        # 解码输出\n",
    "        tokens = en_tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "        print(\"翻译结果:\", tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3672b523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入中文进行翻译（输入 'exit' 退出）:\n",
      "翻译结果: ?\n",
      "翻译结果: understand the people , on Economic and , with the Nations agencies to a of the on the of force or on the so , in ,\n",
      "翻译结果: understand the people , on Economic and , with the Nations agencies to a of the on the of force or on the so , in ,\n",
      "翻译结果: understand the people , on Economic and , with the Nations agencies to a of the on the of force or on the so , in ,\n",
      "翻译结果: understand the people , on Economic and , with the Nations agencies to a of the on the of force or on the so , in ,\n",
      "翻译结果: of the General Assembly\n",
      "翻译结果: understand the people , on Economic and , with the Nations agencies to a of the on the of force or on the so , in ,\n",
      "翻译结果: understand the people , on Economic and , with the Nations agencies to a of the on the of force or on the so , in ,\n",
      "翻译结果: understand the people , on Economic and , with the Nations agencies to a of the on the of force or on the so , in ,\n",
      "翻译结果: understand the people , on Economic and , with the Nations agencies to a of the on the of force or on the so , in ,\n"
     ]
    }
   ],
   "source": [
    "# 加载已保存的模型\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "loaded_model, zh_tok, en_tok = load_model(device=device)\n",
    "\n",
    "# 启动交互翻译\n",
    "interactive_translate(loaded_model, zh_tok, en_tok, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4979808",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c64abb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
