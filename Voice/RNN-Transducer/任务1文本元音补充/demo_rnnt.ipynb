{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 说明\n",
    "\n",
    "一个 RNN Transducer的示例，实现一个类似于语言翻译的序列到序列的任务；\n",
    "\n",
    "输入为一段文本序列X，输出为另一个文本序列Y；\n",
    "\n",
    "相当于是一个元音补全的任务：\n",
    "\n",
    "例如： X: Hll,Wrld --> Y: Hello,World"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import unidecode\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62015"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters = \"AEIOUaeiou\"\n",
    "Embedding_dim = 1024\n",
    "Predictor_dim = 1024\n",
    "Joiner_dim = 1024\n",
    "\n",
    "\n",
    "with open(\"war_and_peace.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "len_txt = len(lines)\n",
    "\n",
    "len_txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TxtDataset(Dataset):\n",
    "\n",
    "    def __init__(self, lines):\n",
    "        super().__init__()\n",
    "        self.lines = lines\n",
    "\n",
    "    def encode_string(self, line):\n",
    "        return [string.printable.find(x) + 1 for x in line] # 因为0表示blank，所以要加1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lines)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        line = self.lines[index].replace(\"\\n\", \"\")\n",
    "        line = unidecode.unidecode(line)  # 去除特殊字符\n",
    "        x = ''.join([x for x in line if x not in characters])\n",
    "        y = line\n",
    "\n",
    "        x = self.encode_string(x)\n",
    "        y = self.encode_string(y)\n",
    "\n",
    "        x = torch.tensor(x, dtype=torch.long)\n",
    "        y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "        T = torch.full(size=(1,), fill_value=len(x), dtype=torch.long)  # 时间序列的长度\n",
    "        U = torch.full(size=(1,), fill_value=len(y), dtype=torch.long)  # 目标序列的长度\n",
    "\n",
    "        return x, y, T, U\n",
    "    \n",
    "\n",
    "class CustomCollate:\n",
    "    '''\n",
    "    通过定义一个自定义的 Collate 类来解决 DataLoader 中不同长度数据无法堆叠的问题。\n",
    "    '''\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        # 拆包batch的数据\n",
    "        x_list, y_list, T_list, U_list = zip(*batch)\n",
    "\n",
    "        # 对x和y进行填充， 填充为0，0视作为blank\n",
    "        x_padded = pad_sequence(x_list, batch_first=True, padding_value=0)\n",
    "        y_padded = pad_sequence(y_list, batch_first=True, padding_value=0)\n",
    "\n",
    "        # 将T和U转换为张量\n",
    "        T = torch.stack(T_list)\n",
    "        U = torch.stack(U_list)\n",
    "\n",
    "        return x_padded, y_padded, T, U\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ \\t\\n\\r\\x0b\\x0c'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.printable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Wll, Prnc, s Gn nd Lcc r nw jst fmly stts f th\n",
      "\"Well, Prince, so Genoa and Lucca are now just family estates of the\n",
      "tensor([47]) tensor([68])\n"
     ]
    }
   ],
   "source": [
    "def decode_string(lst):\n",
    "    return \"\".join(string.printable[x - 1] for x in lst)\n",
    "\n",
    "train_dataset = TxtDataset(lines[: round(0.9 * len_txt)])\n",
    "x, y, T, U = train_dataset[0]\n",
    "\n",
    "print(decode_string(x))\n",
    "print(decode_string(y))\n",
    "print(T, U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "collate  = CustomCollate()\n",
    "train_dataset = TxtDataset(lines[: round(0.9 * len_txt)])\n",
    "valid_dataset = TxtDataset(lines[round(0.9 * len_txt): ])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, num_workers=0, collate_fn=collate)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, num_workers=0, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 54]),\n",
       " torch.Size([128, 72]),\n",
       " torch.Size([128, 1]),\n",
       " torch.Size([128, 1]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_iter = iter(valid_dataloader)\n",
    "x, y, T, U = next(valid_iter)\n",
    "x.shape, y.shape, T.shape, U.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    '''\n",
    "    对应声学模型\n",
    "    '''\n",
    "    def __init__(self, num_chars = len(string.printable) + 1):\n",
    "        super().__init__()\n",
    "        self.num_chars = num_chars\n",
    "        self.embd = nn.Embedding(num_chars, Embedding_dim)\n",
    "        self.rnn = nn.LSTM(input_size=Embedding_dim, hidden_size=Embedding_dim, num_layers=3, bidirectional=True)\n",
    "        self.lc = nn.Linear(Embedding_dim * 2, Joiner_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x input: [batch, time_step]\n",
    "        x = self.embd(x)   #[batch, time_step, embdding_dim]\n",
    "        x, _ = self.rnn(x)  #[batch, time_step, embdding_dim * 2]\n",
    "        x = self.lc(x)  #[batch, time_step, Joiner_dim]\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class PredNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_chars = len(string.printable) + 1):\n",
    "        super().__init__()\n",
    "        self.embd = nn.Embedding(num_chars, Predictor_dim)\n",
    "        self.rnn = nn.GRUCell(input_size=Predictor_dim, hidden_size=Predictor_dim)\n",
    "        self.lc = nn.Linear(Predictor_dim, Joiner_dim)\n",
    "\n",
    "        self.initial_state = nn.Parameter(torch.randn(Predictor_dim))  # torch.randn 生成标准正态分布\n",
    "        self.start_symbol = 0 # 0表示blank\n",
    "\n",
    "    def forward_one_step(self, input, previous_state):\n",
    "        embedding = self.embd(input) # embedding.shape: [batch， Predicotr_dim]\n",
    "        state = self.rnn(embedding, previous_state) # state.shape: [batch, Predictor_dim]\n",
    "        out = self.lc(state)  # out.shape: [batch, Jointer_dim]\n",
    "        return out, state\n",
    "\n",
    "    def forward(self, y):\n",
    "        # y: [batch, target_num_words]\n",
    "        batch_size = y.shape[0]\n",
    "        U = y.shape[1]\n",
    "        outs = []\n",
    "        state = torch.stack([self.initial_state] * batch_size).to(y.device)  # state.shape : [batch, pred_dim]\n",
    "        for u in range(U + 1):\n",
    "            if u == 0:\n",
    "                decoder_input = torch.tensor([self.start_symbol] * batch_size, device=y.device)  # decoder_input: [batch], 就一个维度\n",
    "            else:\n",
    "                decoder_input = y[:, u-1]  # decoder_input: [batch], 就一个维度\n",
    "\n",
    "            out, state = self.forward_one_step(decoder_input, state)\n",
    "            outs.append(out)\n",
    "\n",
    "        out = torch.stack(outs, dim=1)  # out.shape [batch, U + 1, Jointer_dim]\n",
    "        return out\n",
    "    \n",
    "\n",
    "class Jointer(nn.Module):\n",
    "\n",
    "    def __init__(self, num_chars = len(string.printable) + 1):\n",
    "        super().__init__()\n",
    "        self.lc = nn.Linear(Joiner_dim, num_chars)\n",
    "\n",
    "    def forward(self, encoder_out, pred_out):\n",
    "        # encoder_out: [batch, time_step,  1, num_output]\n",
    "        # pred_out: [batch, 1, target_words_len + 1, num_output]\n",
    "\n",
    "        out = encoder_out + pred_out\n",
    "        # out = torch.cat((encoder_out, pred_out), dim=-1)\n",
    "        out = F.relu(out)\n",
    "        out = self.lc(out)\n",
    "        return F.log_softmax(out, dim=-1) # [batch, time_step, target_words_len + 1, num_output]\n",
    "    \n",
    "\n",
    "class Transducer(nn.Module):\n",
    "\n",
    "    def __init__(self, num_input, num_output):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(num_input)\n",
    "        self.pred_net = PredNet(num_output)\n",
    "        self.jointer = Jointer(num_output)\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, x, y, T, U):\n",
    "        '''\n",
    "        T: 时间序列的长度\n",
    "        U: 目标序列的长度\n",
    "        '''\n",
    "        encoder_out = self.encoder(x)  # [batch, time_step, Joiner_dim]\n",
    "        pred_out = self.pred_net(y)    # [batch, target_words_len + 1, Joiner_dim]\n",
    "        joiner_out = self.jointer(encoder_out.unsqueeze(2), pred_out.unsqueeze(1)) \n",
    "        return joiner_out # [batch, time_step, target_words_len + 1, num_output]\n",
    "    \n",
    "    #  Transducer.comput_single_alignment_prob = comput_single_alignment_prob\n",
    "    def greedy_search(self, x, T):\n",
    "        y_batch = []\n",
    "        B = len(x)\n",
    "        encoder_out = self.encoder.forward(x)\n",
    "        U_max = 200\n",
    "        for b in range(B):\n",
    "            t = 0; u = 0; y = [self.pred_net.start_symbol]; \n",
    "            predictor_state = self.pred_net.initial_state.unsqueeze(0)\n",
    "            while t < T[b] and u < U_max:\n",
    "                predictor_input = torch.tensor([ y[-1] ], device = x.device)\n",
    "                g_u, predictor_state = self.pred_net.forward_one_step(predictor_input, predictor_state)\n",
    "                f_t = encoder_out[b, t]\n",
    "                h_t_u = self.jointer.forward(f_t, g_u)\n",
    "                argmax = h_t_u.max(-1)[1].item()\n",
    "                if argmax == 0:\n",
    "                    t += 1\n",
    "                else: # argmax == a label\n",
    "                    u += 1\n",
    "                    y.append(argmax)\n",
    "            y_batch.append(y[1:]) # remove start symbol\n",
    "        return y_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 54, 73, 101])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnnt = Transducer(len(string.printable) + 1, len(string.printable) + 1)\n",
    "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "rnnt(x, y, T, U).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNTLoss(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, logits, y, T, U):\n",
    "        '''\n",
    "        logits: [batch, time_step, target_words_len, num_outputs] , 预测分布\n",
    "        y: target_token: [batch, target_words_len]\n",
    "        T: time_step: 输入序列长度，T\n",
    "        U: target_words_len: 目标序列长度 U\n",
    "        '''\n",
    "\n",
    "        batch_size, T_max, U_max, vocab_size = logits.shape\n",
    "        log_alpha = torch.zeros(batch_size, T_max, U_max, device=logits.device)\n",
    "        # log_alpha[t, u]：表示在时刻 t 和目标位置 u 的对数概率。该值的大小表示从输入序列的开始到当前位置的路径的概率。\n",
    "        for t in range(T_max):\n",
    "            for u in range(U_max):\n",
    "                if u == 0:\n",
    "                    if t == 0:\n",
    "                        log_alpha[:, t, u] = 0.\n",
    "                    else: # t > 0\n",
    "                        log_alpha[:, t, u] = log_alpha[:, t-1, u] + logits[:, t-1, 0, 0] #logits[:, t-1, 0, 0]： 在t-1时刻，在预测第0个单词的时候，预测是blank的概率\n",
    "                else: # u > 0\n",
    "                    if t == 0:\n",
    "                        # torch.gather(input, dim, index) 是 PyTorch 中的一个函数，用于根据给定的 index 张量从 input 张量中按指定维度（dim）选取数据。\n",
    "                        # log_alpha[:, t, u-1]: [batch, vocab_size]\n",
    "                        # y[:, u-1].view(-1, 1)): [batch, 1]\n",
    "                        # log_alpha[:, t, u-1]: [batch]\n",
    "                        log_alpha[:, t, u] = log_alpha[:, t, u-1] + torch.gather(logits[:, t, u-1], dim=1, index=y[:, u-1].view(-1, 1)).reshape(-1)\n",
    "                    else: # t > 0\n",
    "                        log_alpha[:, t, u] = torch.logsumexp(torch.stack([\n",
    "                            log_alpha[:, t-1, u] + logits[:, t-1, u, 0],\n",
    "                            log_alpha[:, t, u-1] + torch.gather(logits[:, t, u-1], dim=1, index=y[:, u-1].view(-1, 1)).reshape(-1)\n",
    "                        ]), dim=0) # 这一段写的太妙了，然后为了logsumexp可以正确使用，我们需要对两部分转移过来的数组进行stack，拼接成一个之后，指定dim就可以正确处理了。这个dim的逻辑就和sum的axis逻辑一样\n",
    "\n",
    "            log_probs = []\n",
    "            for b in range(batch_size):\n",
    "                log_prob = log_alpha[b, T[b]-1, U[b]] + logits[b, T[b]-1, U[b], 0]  # 虽然padding之后所有长度都一样了，但是我们自己知道，我们需要的长度其实是T和U\n",
    "                log_probs.append(log_prob)\n",
    "            log_probs = torch.stack(log_probs)\n",
    "\n",
    "            return -log_probs.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, epoch, dataloader):\n",
    "    model.train()\n",
    "    loss_mean = 0\n",
    "    with tqdm(dataloader) as pbar:\n",
    "        for batch_index, (x, y, T, U) in enumerate(pbar):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            T, U = T.to(device), U.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output_log_softmax = model(x, y, T, U)  # [seq_len, batch, label]\n",
    "\n",
    "            # target: [batch, num_words_len]\n",
    "            loss = loss_fn(output_log_softmax, y, T, U)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss = loss.item()\n",
    "\n",
    "            if batch_index == 0:\n",
    "                loss_mean = loss\n",
    "\n",
    "            loss_mean = 0.1 * loss + 0.9 * loss_mean\n",
    "\n",
    "            pbar.set_description(f'Epoch {epoch} Loss: {loss_mean:.4f}')\n",
    "\n",
    "            if batch_index % 30 == 0:\n",
    "                model.eval()\n",
    "                guesses = model.greedy_search(x, T)\n",
    "                model.train()\n",
    "                print(\"\\n\")\n",
    "                for b in range(2):\n",
    "                    print(\"input:\", decode_string(x[b,:T[b]]))\n",
    "                    print(\"guess:\", decode_string(guesses[b]))\n",
    "                    print(\"truth:\", decode_string(y[b,:U[b]]))\n",
    "                    print(\"\")\n",
    "\n",
    "\n",
    "def valid(model, optimizer, epoch, dataloader):\n",
    "    model.eval()\n",
    "    with tqdm(dataloader) as pbar, torch.no_grad():\n",
    "        loss_sum = 0\n",
    "        acc_sum = 0\n",
    "        for batch_index, (data, target, input_lengths, target_lengths) in enumerate(pbar):\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            output = model(data)\n",
    "            output_log_softmax = F.log_softmax(output, dim=-1)\n",
    "            loss = F.ctc_loss(output_log_softmax, target, input_lengths, target_lengths)\n",
    "\n",
    "            loss = loss.item()\n",
    "            acc = calc_acc(target, output)\n",
    "\n",
    "            loss_sum += loss\n",
    "            acc_sum += acc\n",
    "\n",
    "            loss_mean = loss_sum / (batch_index + 1)\n",
    "            acc_mean = acc_sum / (batch_index + 1)\n",
    "\n",
    "            pbar.set_description(f'Test : {epoch} Loss: {loss_mean:.4f} Acc: {acc_mean:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: -0.0000:   0%|          | 1/437 [00:01<07:39,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "input: \"Wll, Prnc, s Gn nd Lcc r nw jst fmly stts f th\n",
      "guess: \n",
      "truth: \"Well, Prince, so Genoa and Lucca are now just family estates of the\n",
      "\n",
      "input: Bnprts. Bt  wrn y, f y dn't tll m tht ths mns wr,\n",
      "guess: \n",
      "truth: Buonapartes. But I warn you, if you don't tell me that this means war,\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.0000:  23%|██▎       | 101/437 [00:35<03:03,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "input: th Hfkrgsrth nd bth mprrs tk prt. t tht cncl, cntrry\n",
      "guess: \n",
      "truth: the Hofkriegsrath and both Emperors took part. At that council, contrary\n",
      "\n",
      "input: t th vws f th ld gnrls Ktzv nd Prnc Schwrtznbrg, t\n",
      "guess: \n",
      "truth: to the views of the old generals Kutuzov and Prince Schwartzenberg, it\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.0000:  30%|███       | 133/437 [00:47<01:47,  2.82it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m rnnt\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrnnt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[63], line 15\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, loss_fn, epoch, dataloader)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# target: [batch, num_words_len]\u001b[39;00m\n\u001b[1;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(output_log_softmax, y, T, U)\n\u001b[0;32m---> 15\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     18\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/anaconda3/envs/DL/lib/python3.11/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/DL/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/DL/lib/python3.11/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(rnnt.parameters(), 0.0003)\n",
    "loss_fn = RNNTLoss()\n",
    "epochs = 15\n",
    "\n",
    "rnnt.to(device)\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(rnnt, optimizer, loss_fn, epoch, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "一个RNN Transducer的示例，实现一个类似语言翻译的序列到序列任务；\n",
    "输入为一段文本序列X，输出为另一个文本序列Y；\n",
    "将Y序列中的元音字符去除即为X。例如：\n",
    " X: Hll, Wrld --> Y：Hello, World\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import string\n",
    "import numpy as np\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import unidecode\n",
    "\n",
    "NULL_INDEX = 0\n",
    "\n",
    "encoder_dim   = 1024\n",
    "predictor_dim = 1024\n",
    "joiner_dim    = 1024\n",
    "\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, num_inputs):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embed = torch.nn.Embedding(num_inputs, encoder_dim)\n",
    "        self.rnn = torch.nn.GRU(input_size=encoder_dim, hidden_size=encoder_dim, num_layers=3, batch_first=True,bidirectional=True, dropout=0.1)\n",
    "        self.linear = torch.nn.Linear(encoder_dim*2, joiner_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        out = self.embed(out)\n",
    "        out = self.rnn(out)[0]\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "    \n",
    "\n",
    "class Predictor(torch.nn.Module):\n",
    "    def __init__(self, num_outputs):\n",
    "        super(Predictor, self).__init__()\n",
    "        self.embed = torch.nn.Embedding(num_outputs, predictor_dim)\n",
    "        self.rnn = torch.nn.GRUCell(input_size=predictor_dim, hidden_size=predictor_dim)\n",
    "        self.linear = torch.nn.Linear(predictor_dim, joiner_dim)\n",
    "\n",
    "        self.initial_state = torch.nn.Parameter(torch.randn(predictor_dim))\n",
    "        self.start_symbol = NULL_INDEX #原始论文中，使用0向量，这里采用使用null index\n",
    "\n",
    "\n",
    "    def forward_one_step(self, input, previous_state):\n",
    "        embedding = self.embed(input)\n",
    "        state = self.rnn.forward(embedding, previous_state)\n",
    "        out = self.linear(state)\n",
    "        return out, state\n",
    "    \n",
    "    def forward(self, y):\n",
    "        batch_size = y.shape[0]\n",
    "        U = y.shape[1]\n",
    "        outs = []\n",
    "        state = torch.stack([self.initial_state] * batch_size).to(y.device)\n",
    "        for u in range(U+1):\n",
    "            if u == 0:\n",
    "                decoder_input = torch.tensor([self.start_symbol]*batch_size, device=y.device)\n",
    "            else:\n",
    "                decoder_input = y[:,u-1]\n",
    "            out, state = self.forward_one_step(decoder_input, state)\n",
    "            outs.append(out)\n",
    "        out = torch.stack(outs, dim=1)\n",
    "        return out\n",
    "    \n",
    "\n",
    "class Joiner(torch.nn.Module):\n",
    "    def __init__(self, num_outputs):\n",
    "        super(Joiner, self).__init__()\n",
    "        self.linear = torch.nn.Linear(joiner_dim, num_outputs)\n",
    "\n",
    "    def forward(self, encoder_out, predictor_out):\n",
    "        out = encoder_out + predictor_out\n",
    "        out = torch.nn.functional.relu(out)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "    \n",
    "\n",
    "class Transducer(torch.nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        super(Transducer, self).__init__()\n",
    "        self.encoder = Encoder(num_inputs)\n",
    "        self.predictor = Predictor(num_outputs)\n",
    "        self.joiner = Joiner(num_outputs)\n",
    "\n",
    "        if torch.cuda.is_available(): self.device = \"cuda:0\"\n",
    "        else: self.device = \"cpu\"\n",
    "        self.to(self.device)\n",
    "\n",
    "    def comput_forward_prob(self, joiner_out, T, U, y):\n",
    "        \"\"\"\n",
    "        joiner_out: tensor of shape (B, T_max, U_max+1, #labels)\n",
    "        T: list of input lengths\n",
    "        U: list of output lengths\n",
    "        y: label tensor (B, U_max+1)\n",
    "        \"\"\"\n",
    "\n",
    "        B = joiner_out.shape[0]\n",
    "        T_max = joiner_out.shape[1]\n",
    "        U_max = joiner_out.shape[2] - 1\n",
    "        log_alpha = torch.zeros(B, T_max, U_max+1, device=model.device)\n",
    "        for t in range(T_max):\n",
    "            for u in range(U_max+1):\n",
    "                if u == 0:\n",
    "                    if t == 0:\n",
    "                        log_alpha[:,t,u] = 0.\n",
    "                    else: # t > 0\n",
    "                        log_alpha[:, t, u] = log_alpha[:, t-1, u] + joiner_out[:, t-1, 0, NULL_INDEX]\n",
    "\n",
    "                else: # u > 0\n",
    "                    if t == 0:\n",
    "                        log_alpha[:, t, u] = log_alpha[:, t, u-1] + torch.gather(joiner_out[:,t, u-1], dim=1, index=y[:,u-1].view(-1,1)).reshape(-1)\n",
    "                    else: # t > 0\n",
    "                        log_alpha[:, t, u] = torch.logsumexp(torch.stack([\n",
    "                            log_alpha[:, t-1, u] + joiner_out[:, t-1, u, NULL_INDEX],\n",
    "                            log_alpha[:, t, u-1] + torch.gather(joiner_out[:,t, u-1], dim=1, index=y[:,u-1].view(-1,1) ).reshape(-1)\n",
    "                        ]), dim=0)\n",
    "\n",
    "        log_probs = []\n",
    "        for b in range(B):\n",
    "            log_prob = log_alpha[b, T[b]-1, U[b]] + joiner_out[b, T[b]-1, U[b], NULL_INDEX]\n",
    "            log_probs.append(log_prob)\n",
    "        log_probs = torch.stack(log_probs)\n",
    "        return log_probs\n",
    "\n",
    "    def compute_loss(self, x, y, T, U):\n",
    "        encoder_out = self.encoder.forward(x)\n",
    "        predictor_out = self.predictor.forward(y)\n",
    "        joiner_out = self.joiner.forward(encoder_out.unsqueeze(2), predictor_out.unsqueeze(1)).log_softmax(3)\n",
    "        loss = -self.comput_forward_prob(joiner_out, T, U, y).mean()\n",
    "        return loss\n",
    "\n",
    "#    Transducer.comput_single_alignment_prob = comput_single_alignment_prob\n",
    "    def greedy_search(self, x, T):\n",
    "        y_batch = []\n",
    "        B = len(x)\n",
    "        encoder_out = self.encoder.forward(x)\n",
    "        U_max = 200\n",
    "        for b in range(B):\n",
    "            t = 0; u = 0; y = [self.predictor.start_symbol]; \n",
    "            predictor_state = self.predictor.initial_state.unsqueeze(0)\n",
    "            while t < T[b] and u < U_max:\n",
    "                predictor_input = torch.tensor([ y[-1] ], device = x.device)\n",
    "                g_u, predictor_state = self.predictor.forward_one_step(predictor_input, predictor_state)\n",
    "                f_t = encoder_out[b, t]\n",
    "                h_t_u = self.joiner.forward(f_t, g_u)\n",
    "                argmax = h_t_u.max(-1)[1].item()\n",
    "                if argmax == NULL_INDEX:\n",
    "                    t += 1\n",
    "                else: # argmax == a label\n",
    "                    u += 1\n",
    "                    y.append(argmax)\n",
    "            y_batch.append(y[1:]) # remove start symbol\n",
    "        return y_batch\n",
    "\n",
    "class Collate:\n",
    "    def __call__(self, batch):\n",
    "        \"\"\"\n",
    "        batch: list of tuples (input string, output string)\n",
    "        Returns a minibatch of strings, encoded as labels and padded to have the same length.\n",
    "        \"\"\"\n",
    "        x = []; y = []\n",
    "        batch_size = len(batch)\n",
    "        for index in range(batch_size):\n",
    "            x_, y_ = batch[index]\n",
    "            x.append(encode_string(x_))\n",
    "            y.append(encode_string(y_))\n",
    "\n",
    "        # pad all sequences to have same length\n",
    "        T = [len(x_) for x_ in x]\n",
    "        U = [len(y_) for y_ in y]\n",
    "        T_max = max(T)\n",
    "        U_max = max(U)\n",
    "\n",
    "        for index in range(batch_size):\n",
    "            x[index] += [NULL_INDEX] * (T_max - len(x[index]))\n",
    "            x[index] = torch.tensor(x[index])\n",
    "            y[index] += [NULL_INDEX] * (U_max - len(y[index]))\n",
    "            y[index] = torch.tensor(y[index])\n",
    "\n",
    "        # stack into single tensor\n",
    "        x = torch.stack(x)\n",
    "        y = torch.stack(y)\n",
    "        T = torch.tensor(T)\n",
    "        U = torch.tensor(U)\n",
    "\n",
    "        return (x,y,T,U)\n",
    "    \n",
    "\n",
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, lines, batch_size):\n",
    "        lines = list(filter((\"\\n\").__ne__, lines))\n",
    "        self.lines = lines\n",
    "        collate = Collate()\n",
    "        self.loader = torch.utils.data.DataLoader(self, batch_size=batch_size,num_workers=0,collate_fn=collate)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lines)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        line = self.lines[idx].replace(\"\\n\", \"\")\n",
    "        line = unidecode.unidecode(line)                        # 去除特殊字符 \n",
    "        x = \"\".join(c for c in line if c not in \"AEIOUaeiou\")   # 去除元音字符\n",
    "        y = line\n",
    "        return (x,y)\n",
    "    \n",
    "def encode_string(s):\n",
    "    for c in s:\n",
    "        if c not in string.printable:\n",
    "            print(s)\n",
    "    return [string.printable.index(c) + 1 for c in s]\n",
    "\n",
    "def decode_labels(l):\n",
    "    return \"\".join([string.printable[c-1]  for c in l])\n",
    "\n",
    "class Trainer:\n",
    "  def __init__(self, model, lr):\n",
    "    self.model = model\n",
    "    self.lr = lr\n",
    "    self.optimizer = torch.optim.Adam(model.parameters(), lr=self.lr)\n",
    "  \n",
    "  def train(self, dataset, print_interval = 2):\n",
    "    train_loss = 0\n",
    "    num_samples = 0\n",
    "    self.model.train()\n",
    "    pbar = tqdm(dataset.loader)\n",
    "    for idx, batch in enumerate(pbar):\n",
    "      x,y,T,U = batch\n",
    "      x = x.to(self.model.device); y = y.to(self.model.device)\n",
    "      batch_size = len(x)\n",
    "      num_samples += batch_size\n",
    "      loss = self.model.compute_loss(x,y,T,U)\n",
    "      self.optimizer.zero_grad()\n",
    "      pbar.set_description(\"%.2f\" % loss.item())\n",
    "      loss.backward()\n",
    "      self.optimizer.step()\n",
    "      train_loss += loss.item() * batch_size\n",
    "      if idx % print_interval == 0:\n",
    "        self.model.eval()\n",
    "        guesses = self.model.greedy_search(x,T)\n",
    "        self.model.train()\n",
    "        print(\"\\n\")\n",
    "        for b in range(2):\n",
    "          print(\"input:\", decode_labels(x[b,:T[b]]))\n",
    "          print(\"guess:\", decode_labels(guesses[b]))\n",
    "          print(\"truth:\", decode_labels(y[b,:U[b]]))\n",
    "          print(\"\")\n",
    "    train_loss /= num_samples\n",
    "    return train_loss\n",
    "\n",
    "  def test(self, dataset, print_interval=1):\n",
    "    test_loss = 0\n",
    "    num_samples = 0\n",
    "    self.model.eval()\n",
    "    pbar = tqdm(dataset.loader)\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(pbar):\n",
    "          x,y,T,U = batch\n",
    "          x = x.to(self.model.device); y = y.to(self.model.device)\n",
    "          batch_size = len(x)\n",
    "          num_samples += batch_size\n",
    "          loss = self.model.compute_loss(x,y,T,U)\n",
    "          pbar.set_description(\"%.2f\" % loss.item())\n",
    "          test_loss += loss.item() * batch_size\n",
    "          if idx % print_interval == 0:\n",
    "            print(\"\\n\")\n",
    "            print(\"input:\", decode_labels(x[0,:T[0]]))\n",
    "            print(\"guess:\", decode_labels(self.model.greedy_search(x,T)[0]))\n",
    "            print(\"truth:\", decode_labels(y[0,:U[0]]))\n",
    "            print(\"\")\n",
    "    test_loss /= num_samples\n",
    "    return test_loss\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "407.60:   0%|          | 1/355 [00:15<1:32:31, 15.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "input: \"Wll, Prnc, s Gn nd Lcc r nw jst fmly stts f th\n",
      "guess: \n",
      "truth: \"Well, Prince, so Genoa and Lucca are now just family estates of the\n",
      "\n",
      "input: Bnprts. Bt  wrn y, f y dn't tll m tht ths mns wr,\n",
      "guess: \n",
      "truth: Buonapartes. But I warn you, if you don't tell me that this means war,\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29.38:  28%|██▊       | 101/355 [23:25<54:25, 12.86s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "input: f Rstv n th clb prch.\n",
      "guess: of Rost in the cl perch.\n",
      "truth: of Rostov in the club porch.\n",
      "\n",
      "input: \"nd d y fl qt clm?\" Rstv skd.\n",
      "guess: \"ane do you fel quit coul?\" Rost soke.\n",
      "truth: \"And do you feel quite calm?\" Rostov asked.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20.28:  57%|█████▋    | 201/355 [44:28<32:47, 12.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "input: lck hng dwn n th mddl f hs brd frhd. Hs plmp wht nck\n",
      "guess: lack hing down in th midle of his bred ferhed. His plem what neck\n",
      "truth: lock hung down in the middle of his broad forehead. His plump white neck\n",
      "\n",
      "input: std t shrply bv th blck cllr f hs nfrm, nd h smlld\n",
      "guess: sted to sherly beve th bl caller of his niform, ane he smaled\n",
      "truth: stood out sharply above the black collar of his uniform, and he smelled\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.54:  85%|████████▍ | 301/355 [1:05:48<12:07, 13.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "input: cnsdrtns.\n",
      "guess: considertions.\n",
      "truth: considerations.\n",
      "\n",
      "input: n th thrd f Sptmbr Prr wk lt. Hs hd ws chng, th\n",
      "guess: in the there of Sptember Pierre wek lat. His had was ching, the\n",
      "truth: On the third of September Pierre awoke late. His head was aching, the\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13.69: 100%|██████████| 355/355 [1:17:05<00:00, 13.03s/it]\n",
      "13.47:   0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "input: \"Bt thy dn't ndrstnd r tlk t ll,\" sd th dncr wth \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13.47:   2%|▏         | 1/41 [00:01<01:01,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guess: \"But thy don' unerstened or tak it al,\" said the dancer with a\n",
      "truth: \"But they don't understand our talk at all,\" said the dancer with a\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15.11: 100%|██████████| 41/41 [00:12<00:00,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss = 39.060191, test loss = 14.164064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"war_and_peace.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "end = round(0.9 * len(lines))\n",
    "train_lines = lines[:end]\n",
    "test_lines = lines[end:]\n",
    "train_set = TextDataset(train_lines, batch_size=128)\n",
    "test_set = TextDataset(test_lines, batch_size=128)\n",
    "train_set.__getitem__(0)\n",
    "\n",
    "num_chars = len(string.printable)\n",
    "model = Transducer(num_inputs=num_chars+1, num_outputs=num_chars+1)\n",
    "print(model.device)\n",
    "trainer = Trainer(model=model, lr=0.0003)\n",
    "\n",
    "num_epochs = 1\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = trainer.train(train_set, print_interval=100)\n",
    "    test_loss = trainer.test(test_set, print_interval=100)\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    print(\"Epoch %d: train loss = %f, test loss = %f\" %(epoch, train_loss, test_loss)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'rnnt.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
